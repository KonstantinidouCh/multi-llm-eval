# Multi-LLM Eval Configuration

# Groq API (https://console.groq.com)
GROQ_API_KEY=your_groq_api_key_here

# HuggingFace (https://huggingface.co/settings/tokens)
HUGGINGFACE_API_KEY=your_huggingface_api_key_here

# Google Gemini API (https://aistudio.google.com/apikey)
GEMINI_API_KEY=your_gemini_api_key_here

# Ollama (local installation)
OLLAMA_BASE_URL=http://localhost:11434

# PostgreSQL Database
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=llmeval
POSTGRES_PASSWORD=llmeval
POSTGRES_DB=llmeval

# Langfuse Observability (https://langfuse.com)
# For local setup:
#   1. Run: docker compose up langfuse-web langfuse-worker -d
#   2. Open: http://localhost:3001
#   3. Create account and project
#   4. Get API keys from: Settings > API Keys
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key_here
LANGFUSE_SECRET_KEY=your_langfuse_secret_key_here
# Use http://localhost:3001 when running backend locally
# Use http://langfuse-web:3000 when running backend in Docker
LANGFUSE_HOST=http://localhost:3001
